{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1642828349419,
     "user": {
      "displayName": "ÏñëÏàòÎπà",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "5hYUMeCL51AQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .support_message_main_box {\n",
       "                position: relative;\n",
       "                display: table-cell;\n",
       "                vertical-align: middle;\n",
       "                width: 100%;\n",
       "                height: 8em;\n",
       "                padding: 1em;\n",
       "                padding-left: 11em;\n",
       "                background-color: #f7f7f7;\n",
       "                border: 1px solid #cfcfcf;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            .support_message_main_box img {\n",
       "                position: absolute;\n",
       "                height: 9em;\n",
       "                width: 9em;\n",
       "                left: 0.5em;\n",
       "                top: 0.5em;\n",
       "                border-radius: 1em;\n",
       "            }\n",
       "        </style>\n",
       "        <div class=\"support_message_main_box\">\n",
       "            <img src=\"https://avatars.githubusercontent.com/u/7738570?v=4\" />\n",
       "            <p>\n",
       "            <b>Hi!</b><br/>\n",
       "            <span>I am the author of\n",
       "            <a href=\"https://github.com/LucaCappelletti94/silence_tensorflow\" target=\"_blank\">\n",
       "                silence_tensorflow\n",
       "            </a>, which you use in this Notebook.\n",
       "            </span><br/>\n",
       "            \n",
       "        <span>I hope my work has saved you some time!</span><br/>\n",
       "        \n",
       "            <span>I love to code, but I also need coffee.</span>\n",
       "            <a href=\"https://github.com/sponsors/LucaCappelletti94\" target=\"_blank\">\n",
       "                Please sponsor me on GitHub ‚ù§Ô∏è\n",
       "            </a><br/>\n",
       "            <i>Good luck in your coding üçÄ!</i>\n",
       "            <br/>\n",
       "            <i>- Luca</i>\n",
       "            </p>\n",
       "        <div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm\n",
    "from warnings import filterwarnings\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "filterwarnings('ignore')\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\LDL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<Ïù¥ÏÉÅÏßÄÏßàÌòàÏ¶ù ÏûÑÏÉÅÏ†Å Ï†ïÏÉÅ Î≤îÏúÑ>\n",
    "TC 200mg/dl ÎØ∏Îßå\n",
    "LDL 100mg/dl ÎØ∏Îßå\n",
    "TG 150mg/dl ÎØ∏Îßå\n",
    "HDL 40mg/dl Ï¥àÍ≥º\n",
    "\n",
    "*tc Í≥ÑÏÇ∞Î≤ï = HDL ÏΩúÎ†àÏä§ÌÖåÎ°§+LDL ÏΩúÎ†àÏä§ÌÖåÎ°§+Ï§ëÏÑ±ÏßÄÎ∞©/5\n",
    "\n",
    "TC ~99 ÎÇÆÏùå, 100~169 Î≥¥ÌÜµ,  170~199 ÏúÑÌóò, 200~ Ïù¥ÏÉÅ\n",
    "LDL ~49 ÎÇÆÏùå, 50~69 Î≥¥ÌÜµ, 70~99 ÏúÑÌóò, 100~ Ïù¥ÏÉÅ\n",
    "TG ~69 ÎÇÆÏùå,70~119 Î≥¥ÌÜµ, 120~149 ÏúÑÌóò, 150~ Ïù¥ÏÉÅ\n",
    "HDL 60~ ÎÜíÏùå, 50~59 Î≥¥ÌÜµ, 49~41 ÏúÑÌóò, ~40 Ïù¥ÏÉÅ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv, model LOAD\n",
    "df_scaler=pd.read_csv(\"./hyperlipidemia_scaler_4categorical.csv\")\n",
    "df_scaler=df_scaler.drop([df_scaler.columns[0]], axis=1)\n",
    "\n",
    "model_1 = tf.keras.models.load_model('DNN_LDL_4categorical.h5')\n",
    "model_2= tf.keras.models.load_model('DNN_HDL_4categorical.h5')\n",
    "model_3= tf.keras.models.load_model('DNN_TG_4categorical.h5')\n",
    "model_4= tf.keras.models.load_model('DNN_TC_4categorical.h5')\n",
    "model_5= tf.keras.models.load_model('DNN_LDL_4categorical(model_5)_forprediction_HDL.h5')\n",
    "model_6= tf.keras.models.load_model('DNN_LDL_4categorical(model_6)_forprediction_TG.h5')\n",
    "model_7= tf.keras.models.load_model('DNN_LDL_4categorical(model_7)_forprediction_TC.h5')\n",
    "model_8= tf.keras.models.load_model('DNN_LDL_4categorical(model_8)_forprediction_LDL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_1=\"LDL\"\n",
    "id_2=\"HDL\"\n",
    "id_3=\"TG\"\n",
    "id_4=\"TC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ïÌôïÎèÑ Î∞∞Ïó¥\n",
    "accuracy_list=[0 for i in range(8)]\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Í∞úÏàò Î∞∞Ïó¥\n",
    "class_list=[[0]*4 for i in range(8)]\n",
    "\n",
    "#Í∞Å ÌäπÏßïÎ≥Ñ x,y ÏÉùÏÑ±\n",
    "X_onlybody=df_scaler.drop(['LDL', 'HDL', 'TG', 'TC'], axis=1) #Ïã†Ï≤¥Í≥ÑÏ∏°ÏπòÎ°úÎßå Íµ¨ÏÑ±\n",
    "X_onlybody=np.array(X_onlybody)\n",
    "\n",
    "Y_model_1=np.array(df_scaler[id_1])\n",
    "Y_model_1=np.array(Y_model_1)\n",
    "\n",
    "Y_model_2=np.array(df_scaler[id_2])\n",
    "Y_model_2=np.array(Y_model_2)\n",
    "\n",
    "Y_model_3=np.array(df_scaler[id_3])\n",
    "Y_model_3=np.array(Y_model_3)\n",
    "\n",
    "Y_model_4=np.array(df_scaler[id_4])\n",
    "Y_model_4=np.array(Y_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥Í≥ÑÏ∏°ÏπòÎ•º Ïù¥Ïö©Ìï¥ ÏòàÏ∏°Ìïú model_1 ÌäπÏßï ÏàòÏπò>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1642828358072,
     "user": {
      "displayName": "ÏñëÏàòÎπà",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "fUC5ejGS51Aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7703 - accuracy: 0.6703\n",
      "15/15 [==============================] - 0s 497us/step\n"
     ]
    }
   ],
   "source": [
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_1, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[0]=round((model_1.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_1=model_1.predict(X_onlybody)\n",
    "\n",
    "predict_model_1_list=[]\n",
    "for li in predict_model_1:\n",
    "    index=li.argmax()\n",
    "    predict_model_1_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[0][i]=predict_model_1_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥Í≥ÑÏ∏°ÏπòÎ•º Ïù¥Ïö©Ìï¥ ÏòàÏ∏°Ìïú model_2 ÌäπÏßï ÏàòÏπò>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.5604\n",
      "15/15 [==============================] - 0s 572us/step\n"
     ]
    }
   ],
   "source": [
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_2, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[1]=round((model_2.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_2=model_2.predict(X_onlybody)\n",
    "\n",
    "predict_model_2_list=[]\n",
    "for li in predict_model_2:\n",
    "    index=li.argmax()\n",
    "    predict_model_2_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[1][i]=predict_model_2_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥Í≥ÑÏ∏°ÏπòÎ•º Ïù¥Ïö©Ìï¥ ÏòàÏ∏°Ìïú model_3 ÌäπÏßï ÏàòÏπò>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1642828358072,
     "user": {
      "displayName": "ÏñëÏàòÎπà",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "fUC5ejGS51Aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 2.2007 - accuracy: 0.5385\n",
      "15/15 [==============================] - 0s 643us/step\n"
     ]
    }
   ],
   "source": [
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_3, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[2]=round((model_3.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_3=model_3.predict(X_onlybody)\n",
    "\n",
    "predict_model_3_list=[]\n",
    "for li in predict_model_3:\n",
    "    index=li.argmax()\n",
    "    predict_model_3_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[2][i]=predict_model_3_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥Í≥ÑÏ∏°ÏπòÎ•º Ïù¥Ïö©Ìï¥ ÏòàÏ∏°Ìïú model_4 ÌäπÏßï ÏàòÏπò>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 4.2557 - accuracy: 0.4945\n",
      "15/15 [==============================] - 0s 500us/step\n"
     ]
    }
   ],
   "source": [
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_4, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[3]=round((model_4.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_4=model_4.predict(X_onlybody)\n",
    "\n",
    "predict_model_4_list=[]\n",
    "for li in predict_model_4:\n",
    "    index=li.argmax()\n",
    "    predict_model_4_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[3][i]=predict_model_4_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====test-Ïã†Ï≤¥+ÏùºÎ∞ò prediction===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model_2_list=np.array(predict_model_2_list, dtype='float64')\n",
    "predict_model_2_list=predict_model_2_list.reshape(-1,1)\n",
    "\n",
    "predict_model_3_list=np.array(predict_model_3_list, dtype='float64')\n",
    "predict_model_3_list=predict_model_3_list.reshape(-1,1)\n",
    "\n",
    "predict_model_4_list=np.array(predict_model_4_list, dtype='float64')\n",
    "predict_model_4_list=predict_model_4_list.reshape(-1,1)\n",
    "\n",
    "X_model_prediction=np.hstack([X_onlybody, predict_model_2_list, predict_model_3_list, predict_model_4_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_prediction,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 6.3328 - accuracy: 0.6374\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.1940 - accuracy: 0.6484\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.1753 - accuracy: 0.6703\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.1753 - accuracy: 0.6703\n",
      "Accuracy: 0.6703\n"
     ]
    }
   ],
   "source": [
    "# DNN_prediction Î™®Îç∏ \n",
    "accuracy_pre=0\n",
    "while accuracy_pre<=0.67:\n",
    "    DNN_prediction = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    DNN_prediction.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    DNN_prediction.fit(x_train, y_train_encoded, epochs=150, batch_size=8, verbose=0)\n",
    "\n",
    "    accuracy_pre=round(DNN_prediction.evaluate(x_test, y_test_encoded)[1],4)\n",
    "    \n",
    "print(\"Accuracy: %.4f\" % (DNN_prediction.evaluate(x_test, y_test_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_prediction.save('DNN_normal_prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====Ï†ïÎãµ ÏàòÏπò ÎÑ£Ïñ¥ÏÑú prediction===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_real=df_scaler.drop(['LDL'], axis=1) #Ïã†Ï≤¥Í≥ÑÏ∏°Ïπò+Ïã§Ï†ú HDL, TG, TC\n",
    "\n",
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_all_real,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 3.3733 - accuracy: 0.8022\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3733 - accuracy: 0.8022\n",
      "Accuracy: 0.8022\n"
     ]
    }
   ],
   "source": [
    "# DNN_prediction Î™®Îç∏ \n",
    "accuracy_real=0\n",
    "while accuracy_real<=0.78:\n",
    "    DNN_real = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    DNN_real.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    DNN_real.fit(x_train, y_train_encoded, epochs=150, batch_size=8, verbose=0)\n",
    "\n",
    "    accuracy_real=round(DNN_real.evaluate(x_test, y_test_encoded)[1],4)\n",
    "    \n",
    "print(\"Accuracy: %.4f\" % (DNN_real.evaluate(x_test, y_test_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_real.save('DNN_real_prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥ + model_1 ÏòàÏ∏°Í∞í -> model_5(id_2 ÏàòÏπò)Î°ú ÏòàÏ∏°>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1213 - accuracy: 0.6044\n",
      "15/15 [==============================] - 0s 571us/step\n"
     ]
    }
   ],
   "source": [
    "#ÏòàÏ∏°Í∞í Î∂ôÏó¨Ï£ºÍ∏∞\n",
    "#X_model_5 = X_onlybody+model_1_prediction\n",
    "predict_model_1_list=np.array(predict_model_1_list, dtype='float64')\n",
    "predict_model_1_list=predict_model_1_list.reshape(-1,1)\n",
    "X_model_5=np.hstack([X_onlybody, predict_model_1_list])\n",
    "\n",
    "\n",
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_5,Y_model_2,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[4]=round((model_5.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_5=model_5.predict(X_model_5)\n",
    "\n",
    "predict_model_5_list=[]\n",
    "for li in predict_model_5:\n",
    "    index=li.argmax()\n",
    "    predict_model_5_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[4][i]=predict_model_5_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥ + model_1&5 ÏòàÏ∏°Í∞í -> model_6(id_3 ÏàòÏπò)Î°ú ÏòàÏ∏°>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 2.5210 - accuracy: 0.5714\n",
      "15/15 [==============================] - 0s 571us/step\n"
     ]
    }
   ],
   "source": [
    "#ÏòàÏ∏°Í∞í Î∂ôÏó¨Ï£ºÍ∏∞\n",
    "#X_model_6 = X_onlybody+model_1 & 5_prediction\n",
    "predict_model_5_list=np.array(predict_model_5_list, dtype='float64')\n",
    "predict_model_5_list=predict_model_5_list.reshape(-1,1)\n",
    "X_model_6=np.hstack([X_onlybody, predict_model_1_list, predict_model_5_list])\n",
    "\n",
    "\n",
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_6,Y_model_3,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[5]=round((model_6.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_6=model_6.predict(X_model_6)\n",
    "\n",
    "predict_model_6_list=[]\n",
    "for li in predict_model_6:\n",
    "    index=li.argmax()\n",
    "    predict_model_6_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[5][i]=predict_model_6_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥ + model_1&5&6 ÏòàÏ∏°Í∞í -> model_7(id_4 ÏàòÏπò)Î°ú ÏòàÏ∏°>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 6.5278 - accuracy: 0.4945\n",
      "15/15 [==============================] - 0s 571us/step\n"
     ]
    }
   ],
   "source": [
    "#ÏòàÏ∏°Í∞í Î∂ôÏó¨Ï£ºÍ∏∞\n",
    "#X_model_7 = X_onlybody+model_1 & 5 & 6_prediction\n",
    "predict_model_6_list=np.array(predict_model_6_list, dtype='float64')\n",
    "predict_model_6_list=predict_model_6_list.reshape(-1,1)\n",
    "X_model_7=np.hstack([X_onlybody, predict_model_1_list, predict_model_5_list, predict_model_6_list])\n",
    "\n",
    "\n",
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_7,Y_model_4,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[6]=round((model_7.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_7=model_7.predict(X_model_7)\n",
    "\n",
    "predict_model_7_list=[]\n",
    "for li in predict_model_7:\n",
    "    index=li.argmax()\n",
    "    predict_model_7_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[6][i]=predict_model_7_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Ïã†Ï≤¥ + model_5&6&7 ÏòàÏ∏°Í∞í -> model_8(id_1 ÏàòÏπò)Î°ú ÏòàÏ∏°>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2265 - accuracy: 0.7363\n",
      "15/15 [==============================] - 0s 571us/step\n"
     ]
    }
   ],
   "source": [
    "#ÏòàÏ∏°Í∞í Î∂ôÏó¨Ï£ºÍ∏∞\n",
    "#X_model_8 = X_onlybody+model_5 & 6 & 7_prediction\n",
    "predict_model_7_list=np.array(predict_model_7_list, dtype='float64')\n",
    "predict_model_7_list=predict_model_7_list.reshape(-1,1)\n",
    "X_model_8=np.hstack([X_onlybody, predict_model_5_list, predict_model_6_list, predict_model_7_list])\n",
    "\n",
    "\n",
    "#train-test Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_8,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[7]=round((model_8.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_8=model_8.predict(X_model_8)\n",
    "\n",
    "predict_model_8_list=[]\n",
    "for li in predict_model_8:\n",
    "    index=li.argmax()\n",
    "    predict_model_8_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[7][i]=predict_model_8_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Í≤∞Í≥º Ï∂úÎ†•>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 accuracy: 67.03%\n",
      "model 2 accuracy: 56.04%\n",
      "model 3 accuracy: 53.85%\n",
      "model 4 accuracy: 49.45%\n",
      "model 5 accuracy: 60.44%\n",
      "model 6 accuracy: 57.14%\n",
      "model 7 accuracy: 49.45%\n",
      "model 8 accuracy: 73.63%\n"
     ]
    }
   ],
   "source": [
    "# Ï†ïÌôïÎèÑ Ï∂úÎ†•\n",
    "for i in range(8):\n",
    "    print(f\"model {i+1} accuracy: {accuracy_list[i]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 class\n",
      "[1, 32, 121, 298]\n",
      "\n",
      "model 2 class\n",
      "[208, 102, 122, 20]\n",
      "\n",
      "model 3 class\n",
      "[145, 180, 53, 74]\n",
      "\n",
      "model 4 class\n",
      "[0, 125, 165, 162]\n",
      "\n",
      "model 5 class\n",
      "[207, 105, 121, 19]\n",
      "\n",
      "model 6 class\n",
      "[148, 171, 59, 74]\n",
      "\n",
      "model 7 class\n",
      "[0, 126, 153, 173]\n",
      "\n",
      "model 8 class\n",
      "[1, 30, 126, 295]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ÌÅ¥ÎûòÏä§ Ï∂úÎ†•\n",
    "for i in range(8):\n",
    "    print(f\"model {i+1} class\")\n",
    "    print(class_list[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bagging_logi_ensemble.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5d60dadaadefcdc8ea71f1b2a7d61f81b140c3ffed39f6be6e95efa72c685b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
